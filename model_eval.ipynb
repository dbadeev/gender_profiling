{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Install libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import csv\n",
    "!pip3 install tensorflow==1.15.4\n",
    "!pip3 install pandas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get bert layer\n",
    "!pip3 install bert-experimental --no-deps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip3 install tensorflow_hub==0.7.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip3 install 'h5py==2.8.0' --force-reinstall\n",
    "!pip3 install 'numpy==1.18.5' --force-reinstall"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Twitter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from razdel import sentenize, tokenize\n",
    "from navec import Navec\n",
    "from slovnet import Morph\n",
    "\n",
    "df = pd.read_csv('test_data_two_columns.csv', sep=\":\")\n",
    "total_posts = df[['post']].count().post\n",
    "res = [2] * total_posts\n",
    "for i in range(0, total_posts):\n",
    "    found_gender = 0\n",
    "    chunk = []\n",
    "    post = ''.join(df[['post']].values[i])\n",
    "    exceptions = (\"http\", \"Источник\", \"художественный перевод\", \"Википедии:\",\".ru\", \"ЖЖ\")\n",
    "    if not(any(word in post for word in exceptions)):\n",
    "        for sent in sentenize(post):\n",
    "            tokens = [_.text for _ in tokenize(sent.text)]\n",
    "            chunk.append(tokens)\n",
    "        navec = Navec.load('navec_news_v1_1B_250K_300d_100q.tar')\n",
    "        morph = Morph.load('slovnet_morph_news_v1.tar', batch_size=4)\n",
    "        morph.navec(navec)\n",
    "        cnt_chunk = chunk.copy()\n",
    "\n",
    "        for sent in chunk:\n",
    "            ya_in_quotes = 0\n",
    "            if sent.count('\"') > 1:\n",
    "                cnt_el_in_sent = 0\n",
    "                total_quotes = sent.count('\"')\n",
    "                while total_quotes > 1: # Change яЯ in quotes\n",
    "                    open_quote = sent.index('\"', cnt_el_in_sent)\n",
    "                    close_quote = sent.index('\"', open_quote + 1)\n",
    "                    while 'я' in sent and open_quote < sent.index('я') < close_quote or \\\n",
    "                            'Я' in sent and open_quote < sent.index('Я') < close_quote:\n",
    "                        if 'я' in sent and open_quote < sent.index('я') < close_quote:\n",
    "                            sent[sent.index('я')] = 'ya'\n",
    "                            ya_in_quotes += 1\n",
    "                        elif 'Я' in sent and open_quote < sent.index('Я') < close_quote:\n",
    "                            sent[sent.index('Я')] = 'YA'\n",
    "                            ya_in_quotes += 1\n",
    "                    total_quotes -= 2\n",
    "                    cnt_el_in_sent = close_quote + 1\n",
    "        m = 0   # for gender 1\n",
    "        w = 0   # for gender 0\n",
    "        for sent in chunk:\n",
    "            if not(sent.count('-') > 0 and sent.index('-') < 3):\n",
    "                if 'я' in sent or 'Я' in sent:\n",
    "                    if 'я' in sent:\n",
    "                        ya_index = sent.index('я')\n",
    "                    else:\n",
    "                        ya_index = sent.index('Я')\n",
    "                    markup = next(morph.map(cnt_chunk))\n",
    "                    for v in sent:\n",
    "                        if (v[-2:] == 'ла' or v[-1:] == 'л' or v[-3:] == 'лся' or v[-4:] == 'лась') \\\n",
    "                                and (markup.tokens[sent.index(v)].pos == 'VERB') \\\n",
    "                                and ya_index <= sent.index(v) <= ya_index + 5 \\\n",
    "                                and (markup.tokens[sent.index(v)].feats.get('Gender') is not None):\n",
    "                            found_gender = 1\n",
    "                            if  v[-2:] == 'ла' or v[-4:] == 'лась':\n",
    "                                w += 1\n",
    "                            elif v[-1:] == 'л' or v[-3:] == 'лся' :\n",
    "                                m += 1\n",
    "                            break\n",
    "            cnt_chunk.pop(0)\n",
    "        if found_gender == 1:\n",
    "            if m > w:\n",
    "                res[i] = 1\n",
    "            elif w > m:\n",
    "                res[i] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from bert_experimental.finetuning.bert_layer import BertLayer\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(\"test_data_two_columns.csv\",sep=\":\")\n",
    "label_encoder1 = LabelEncoder()\n",
    "df1['label'] = label_encoder1.fit_transform(df1.gender.tolist())\n",
    "\n",
    "X1 = df1.post.values\n",
    "L1 = df1.label.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "new_model = load_model(\"/Users/dbadeev/PycharmProjects/gender_cls_copy/cls_model_256.h5\", custom_objects={'BertLayer': BertLayer})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tsp1 = new_model.predict(X1, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted_classes1 = np.argmax(tsp1,axis=1)\n",
    "predicted_classes1_upd = np.argmax(tsp1,axis=1)\n",
    "\n",
    "# check for stylometric diff with model prediction\n",
    "for i in range (0, len(predicted_classes1)):\n",
    "    if res[i] != predicted_classes1[i] and res[i] != 2:\n",
    "        print(\"DIFF - \", i, res[i], \" stylo - model \", predicted_classes1[i], \"\\n\")\n",
    "\n",
    "for i in range (0, len(predicted_classes1)):\n",
    "    if res[i] != predicted_classes1_upd[i] and res[i] != 2:\n",
    "        predicted_classes1_upd[i] = res[i]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check for stylometric diff with true value\n",
    "for i in range (0, len(L1)):\n",
    "    if res[i] != L1[i] and res[i] != 2:\n",
    "        print(\"ALARM!!! - \", i, res[i], L1[i], \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#model prediction\n",
    "print(classification_report(L1, predicted_classes1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#model+stylometry prediction\n",
    "print(classification_report(L1, predicted_classes1_upd))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Facebook"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from razdel import sentenize, tokenize\n",
    "from navec import Navec\n",
    "from slovnet import Morph\n",
    "\n",
    "df = pd.read_csv('fb_data_two_columns.csv', sep=\":\")\n",
    "total_posts = df[['post']].count().post\n",
    "res = [2] * total_posts\n",
    "for i in range(0, total_posts):\n",
    "    found_gender = 0\n",
    "    chunk = []\n",
    "    post = ''.join(df[['post']].values[i])\n",
    "    exceptions = (\"http\", \"Источник\", \"художественный перевод\", \"Википедии:\",\".ru\", \"ЖЖ\")\n",
    "    if not(any(word in post for word in exceptions)):\n",
    "        for sent in sentenize(post):\n",
    "            tokens = [_.text for _ in tokenize(sent.text)]\n",
    "            chunk.append(tokens)\n",
    "        navec = Navec.load('navec_news_v1_1B_250K_300d_100q.tar')\n",
    "        morph = Morph.load('slovnet_morph_news_v1.tar', batch_size=4)\n",
    "        morph.navec(navec)\n",
    "        cnt_chunk = chunk.copy()\n",
    "\n",
    "        for sent in chunk:\n",
    "            ya_in_quotes = 0\n",
    "            if sent.count('\"') > 1:\n",
    "                cnt_el_in_sent = 0\n",
    "                total_quotes = sent.count('\"')\n",
    "                while total_quotes > 1: # Change яЯ in quotes\n",
    "                    open_quote = sent.index('\"', cnt_el_in_sent)\n",
    "                    close_quote = sent.index('\"', open_quote + 1)\n",
    "                    while 'я' in sent and open_quote < sent.index('я') < close_quote or \\\n",
    "                            'Я' in sent and open_quote < sent.index('Я') < close_quote:\n",
    "                        if 'я' in sent and open_quote < sent.index('я') < close_quote:\n",
    "                            sent[sent.index('я')] = 'ya'\n",
    "                            ya_in_quotes += 1\n",
    "                        elif 'Я' in sent and open_quote < sent.index('Я') < close_quote:\n",
    "                            sent[sent.index('Я')] = 'YA'\n",
    "                            ya_in_quotes += 1\n",
    "                    total_quotes -= 2\n",
    "                    cnt_el_in_sent = close_quote + 1\n",
    "        m = 0   # for gender 1\n",
    "        w = 0   # for gender 0\n",
    "        for sent in chunk:\n",
    "            if not(sent.count('-') > 0 and sent.index('-') < 3):\n",
    "                if 'я' in sent or 'Я' in sent:\n",
    "                    if 'я' in sent:\n",
    "                        ya_index = sent.index('я')\n",
    "                    else:\n",
    "                        ya_index = sent.index('Я')\n",
    "                    markup = next(morph.map(cnt_chunk))\n",
    "                    for v in sent:\n",
    "                        if (v[-2:] == 'ла' or v[-1:] == 'л' or v[-3:] == 'лся' or v[-4:] == 'лась') \\\n",
    "                                and (markup.tokens[sent.index(v)].pos == 'VERB') \\\n",
    "                                and ya_index <= sent.index(v) <= ya_index + 5 \\\n",
    "                                and (markup.tokens[sent.index(v)].feats.get('Gender') is not None):\n",
    "                            found_gender = 1\n",
    "                            if  v[-2:] == 'ла' or v[-4:] == 'лась':\n",
    "                                w += 1\n",
    "                            elif v[-1:] == 'л' or v[-3:] == 'лся' :\n",
    "                                m += 1\n",
    "                            break\n",
    "            cnt_chunk.pop(0)\n",
    "        if found_gender == 1:\n",
    "            if m > w:\n",
    "                res[i] = 1\n",
    "            elif w > m:\n",
    "                res[i] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from bert_experimental.finetuning.bert_layer import BertLayer\n",
    "\n",
    "df1 = pd.read_csv(\"fb_data_two_columns.csv\",sep=\":\")\n",
    "label_encoder1 = LabelEncoder()\n",
    "df1['label'] = label_encoder1.fit_transform(df1.gender.tolist())\n",
    "\n",
    "X1 = df1.post.values\n",
    "L1 = df1.label.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "new_model = load_model(\"/Users/dbadeev/PycharmProjects/gender_cls_copy/cls_model_256.h5\", custom_objects={'BertLayer': BertLayer})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "new_model = load_model(\"/Users/dbadeev/PycharmProjects/gender_cls_copy/cls_middle_model_256.h5\", custom_objects={'BertLayer': BertLayer})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tsp1 = new_model.predict(X1, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted_classes1 = np.argmax(tsp1,axis=1)\n",
    "predicted_classes1_upd = np.argmax(tsp1,axis=1)\n",
    "\n",
    "# check for stylometric diff with model prediction\n",
    "for i in range (0, len(predicted_classes1)):\n",
    "    if res[i] != predicted_classes1[i] and res[i] != 2:\n",
    "        print(\"DIFF - \", i, res[i], \" stylo - model \", predicted_classes1[i], \"\\n\")\n",
    "\n",
    "for i in range (0, len(predicted_classes1)):\n",
    "    if res[i] != predicted_classes1_upd[i] and res[i] != 2:\n",
    "        predicted_classes1_upd[i] = res[i]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check for stylometric diff with true value\n",
    "for i in range (0, len(L1)):\n",
    "    if res[i] != L1[i] and res[i] != 2:\n",
    "        print(\"ALARM!!! - \", i, res[i], L1[i], \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#model prediction\n",
    "print(classification_report(L1, predicted_classes1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#model+stylometry prediction\n",
    "print(classification_report(L1, predicted_classes1_upd))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Essays"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from razdel import sentenize, tokenize\n",
    "from navec import Navec\n",
    "from slovnet import Morph\n",
    "\n",
    "df = pd.read_csv('essays_data_two_columns.csv', sep=\":\")\n",
    "total_posts = df[['post']].count().post\n",
    "res = [2] * total_posts\n",
    "for i in range(0, total_posts):\n",
    "    found_gender = 0\n",
    "    chunk = []\n",
    "    post = ''.join(df[['post']].values[i])\n",
    "    exceptions = (\"http\", \"Источник\", \"художественный перевод\", \"Википедии:\",\".ru\", \"ЖЖ\")\n",
    "    if not(any(word in post for word in exceptions)):\n",
    "        for sent in sentenize(post):\n",
    "            tokens = [_.text for _ in tokenize(sent.text)]\n",
    "            chunk.append(tokens)\n",
    "        navec = Navec.load('navec_news_v1_1B_250K_300d_100q.tar')\n",
    "        morph = Morph.load('slovnet_morph_news_v1.tar', batch_size=4)\n",
    "        morph.navec(navec)\n",
    "        cnt_chunk = chunk.copy()\n",
    "\n",
    "        for sent in chunk:\n",
    "            ya_in_quotes = 0\n",
    "            if sent.count('\"') > 1: # Change яЯ in quotes\n",
    "                cnt_el_in_sent = 0\n",
    "                total_quotes = sent.count('\"')\n",
    "                while total_quotes > 1:\n",
    "                    open_quote = sent.index('\"', cnt_el_in_sent)\n",
    "                    close_quote = sent.index('\"', open_quote + 1)\n",
    "                    while 'я' in sent and open_quote < sent.index('я') < close_quote or \\\n",
    "                            'Я' in sent and open_quote < sent.index('Я') < close_quote:\n",
    "                        if 'я' in sent and open_quote < sent.index('я') < close_quote:\n",
    "                            sent[sent.index('я')] = 'ya'\n",
    "                            ya_in_quotes += 1\n",
    "                        elif 'Я' in sent and open_quote < sent.index('Я') < close_quote:\n",
    "                            sent[sent.index('Я')] = 'YA'\n",
    "                            ya_in_quotes += 1\n",
    "                    total_quotes -= 2\n",
    "                    cnt_el_in_sent = close_quote + 1\n",
    "        m = 0   # for gender 1\n",
    "        w = 0   # for gender 0\n",
    "        for sent in chunk:\n",
    "            if not(sent.count('-') > 0 and sent.index('-') < 3):\n",
    "                if 'я' in sent or 'Я' in sent:\n",
    "                    if 'я' in sent:\n",
    "                        ya_index = sent.index('я')\n",
    "                    else:\n",
    "                        ya_index = sent.index('Я')\n",
    "                    markup = next(morph.map(cnt_chunk))\n",
    "                    for v in sent:\n",
    "                        if (v[-2:] == 'ла' or v[-1:] == 'л' or v[-3:] == 'лся' or v[-4:] == 'лась') \\\n",
    "                                and (markup.tokens[sent.index(v)].pos == 'VERB') \\\n",
    "                                and ya_index <= sent.index(v) <= ya_index + 5 \\\n",
    "                                and (markup.tokens[sent.index(v)].feats.get('Gender') is not None):\n",
    "                            found_gender = 1\n",
    "                            if  v[-2:] == 'ла' or v[-4:] == 'лась':\n",
    "                                w += 1\n",
    "                            elif v[-1:] == 'л' or v[-3:] == 'лся' :\n",
    "                                m += 1\n",
    "                            break\n",
    "            cnt_chunk.pop(0)\n",
    "        if found_gender == 1:\n",
    "            if m > w:\n",
    "                res[i] = 1\n",
    "            elif w > m:\n",
    "                res[i] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from bert_experimental.finetuning.bert_layer import BertLayer\n",
    "\n",
    "df1 = pd.read_csv(\"essays_data_two_columns.csv\",sep=\":\")\n",
    "label_encoder1 = LabelEncoder()\n",
    "df1['label'] = label_encoder1.fit_transform(df1.gender.tolist())\n",
    "\n",
    "X1 = df1.post.values\n",
    "L1 = df1.label.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "new_model = load_model(\"/Users/dbadeev/PycharmProjects/gender_cls_copy/cls_model_256.h5\", custom_objects={'BertLayer': BertLayer})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "new_model = load_model(\"/Users/dbadeev/PycharmProjects/gender_cls_copy/cls_big_model_256.h5\", custom_objects={'BertLayer': BertLayer})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tsp1 = new_model.predict(X1, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted_classes1 = np.argmax(tsp1,axis=1)\n",
    "predicted_classes1_upd = np.argmax(tsp1,axis=1)\n",
    "\n",
    "# check for stylometric diff with model prediction\n",
    "for i in range (0, len(predicted_classes1)):\n",
    "    if res[i] != predicted_classes1[i] and res[i] != 2:\n",
    "        print(\"DIFF - \", i, res[i], \" stylo - model \", predicted_classes1[i], \"\\n\")\n",
    "\n",
    "for i in range (0, len(predicted_classes1)):\n",
    "    if res[i] != predicted_classes1_upd[i] and res[i] != 2:\n",
    "        predicted_classes1_upd[i] = res[i]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check for stylometric diff with true value\n",
    "for i in range (0, len(L1)):\n",
    "    if res[i] != L1[i] and res[i] != 2:\n",
    "        print(\"ALARM!!! - \", i, res[i], L1[i], \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#model prediction\n",
    "print(classification_report(L1, predicted_classes1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#model+stylometry prediction\n",
    "print(classification_report(L1, predicted_classes1_upd))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Reviews"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from razdel import sentenize, tokenize\n",
    "from navec import Navec\n",
    "from slovnet import Morph\n",
    "\n",
    "df = pd.read_csv('reviews_data_two_columns.csv', sep=\":\")\n",
    "total_posts = df[['post']].count().post\n",
    "res = [2] * total_posts\n",
    "for i in range(0, total_posts):\n",
    "    found_gender = 0\n",
    "    chunk = []\n",
    "    post = ''.join(df[['post']].values[i])\n",
    "    exceptions = (\"http\", \"Источник\", \"художественный перевод\", \"Википедии:\",\".ru\", \"ЖЖ\")\n",
    "    if not(any(word in post for word in exceptions)):\n",
    "        for sent in sentenize(post):\n",
    "            tokens = [_.text for _ in tokenize(sent.text)]\n",
    "            chunk.append(tokens)\n",
    "        navec = Navec.load('navec_news_v1_1B_250K_300d_100q.tar')\n",
    "        morph = Morph.load('slovnet_morph_news_v1.tar', batch_size=4)\n",
    "        morph.navec(navec)\n",
    "        cnt_chunk = chunk.copy()\n",
    "\n",
    "        for sent in chunk:\n",
    "            ya_in_quotes = 0\n",
    "            if sent.count('\"') > 1: # Change яЯ in quotes\n",
    "                cnt_el_in_sent = 0\n",
    "                total_quotes = sent.count('\"')\n",
    "                while total_quotes > 1:\n",
    "                    open_quote = sent.index('\"', cnt_el_in_sent)\n",
    "                    close_quote = sent.index('\"', open_quote + 1)\n",
    "                    while 'я' in sent and open_quote < sent.index('я') < close_quote or \\\n",
    "                            'Я' in sent and open_quote < sent.index('Я') < close_quote:\n",
    "                        if 'я' in sent and open_quote < sent.index('я') < close_quote:\n",
    "                            sent[sent.index('я')] = 'ya'\n",
    "                            ya_in_quotes += 1\n",
    "                        elif 'Я' in sent and open_quote < sent.index('Я') < close_quote:\n",
    "                            sent[sent.index('Я')] = 'YA'\n",
    "                            ya_in_quotes += 1\n",
    "                    total_quotes -= 2\n",
    "                    cnt_el_in_sent = close_quote + 1\n",
    "        m = 0   # for gender 1\n",
    "        w = 0   # for gender 0\n",
    "        for sent in chunk:\n",
    "            if not(sent.count('-') > 0 and sent.index('-') < 3):\n",
    "                if 'я' in sent or 'Я' in sent:\n",
    "                    if 'я' in sent:\n",
    "                        ya_index = sent.index('я')\n",
    "                    else:\n",
    "                        ya_index = sent.index('Я')\n",
    "                    markup = next(morph.map(cnt_chunk))\n",
    "                    for v in sent:\n",
    "                        if (v[-2:] == 'ла' or v[-1:] == 'л' or v[-3:] == 'лся' or v[-4:] == 'лась') \\\n",
    "                                and (markup.tokens[sent.index(v)].pos == 'VERB') \\\n",
    "                                and ya_index <= sent.index(v) <= ya_index + 5 \\\n",
    "                                and (markup.tokens[sent.index(v)].feats.get('Gender') is not None):\n",
    "                            found_gender = 1\n",
    "                            if  v[-2:] == 'ла' or v[-4:] == 'лась':\n",
    "                                w += 1\n",
    "                            elif v[-1:] == 'л' or v[-3:] == 'лся' :\n",
    "                                m += 1\n",
    "                            break\n",
    "            cnt_chunk.pop(0)\n",
    "        if found_gender == 1:\n",
    "            if m > w:\n",
    "                res[i] = 1\n",
    "            elif w > m:\n",
    "                res[i] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from bert_experimental.finetuning.bert_layer import BertLayer\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(\"reviews_data_two_columns.csv\",sep=\":\")\n",
    "label_encoder1 = LabelEncoder()\n",
    "df1['label'] = label_encoder1.fit_transform(df1.gender.tolist())\n",
    "\n",
    "X1 = df1.post.values\n",
    "L1 = df1.label.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "new_model = load_model(\"/Users/dbadeev/PycharmProjects/gender_cls_copy/cls_model_256.h5\", custom_objects={'BertLayer': BertLayer})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "new_model = load_model(\"/Users/dbadeev/PycharmProjects/gender_cls_copy/cls_big_model_256.h5\", custom_objects={'BertLayer': BertLayer})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tsp1 = new_model.predict(X1, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted_classes1 = np.argmax(tsp1,axis=1)\n",
    "predicted_classes1_upd = np.argmax(tsp1,axis=1)\n",
    "\n",
    "# check for stylometric diff with model prediction\n",
    "for i in range (0, len(predicted_classes1)):\n",
    "    if res[i] != predicted_classes1[i] and res[i] != 2:\n",
    "        print(\"DIFF - \", i, res[i], \" stylo - model \", predicted_classes1[i], \"\\n\")\n",
    "\n",
    "\n",
    "for i in range (0, len(predicted_classes1)):\n",
    "    if res[i] != predicted_classes1_upd[i] and res[i] != 2:\n",
    "        predicted_classes1_upd[i] = res[i]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check for stylometric diff with true value\n",
    "for i in range (0, len(L1)):\n",
    "    if res[i] != L1[i] and res[i] != 2:\n",
    "        print(\"ALARM!!! - \", i, res[i], L1[i], \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#model prediction\n",
    "print(classification_report(L1, predicted_classes1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#model+stylometry prediction\n",
    "print(classification_report(L1, predicted_classes1_upd))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Imitations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"imitation_full_data_two_columns.csv\",sep=\":\")\n",
    "label_encoder1 = LabelEncoder()\n",
    "df1['label'] = label_encoder1.fit_transform(df1.gender.tolist())\n",
    "\n",
    "X1 = df1.post.values\n",
    "L1 = df1.label.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "new_model = load_model(\"cls_model.h5\", custom_objects={'BertLayer': BertLayer})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "suoer_big_model = load_model(\"cls_super_big_model.h5\", custom_objects={'BertLayer': BertLayer})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tsp1 = new_model.predict(X1, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicted_classes1 = np.argmax(tsp1,axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#model prediction\n",
    "print(classification_report(L1, predicted_classes1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}